<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Sesión 3- 21 de Mayo de 2020</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/journal.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 61px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h2 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h3 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h4 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h5 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h6 {
  padding-top: 66px;
  margin-top: -66px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Analítica Predictiva</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Introducción</a>
</li>
<li>
  <a href="about.html">Sesiones de clase</a>
</li>
<li>
  <a href="Preguntasrespuestas.html">Preguntas y respuestas</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Sesión 3- 21 de Mayo de 2020</h1>

</div>


<h5>
<strong><span style="color: #808080; font-family: Helvetica; font-size: 12px; font-style: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; background-color: #ffffff; float: none;">Juan David Ospina Arango</span></strong><br style="color: #000000; font-family: Helvetica; font-size: 12px; font-style: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; background-color: #ffffff;" /><em><span style="color: #808080; font-family: Helvetica; font-size: 12px; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; background-color: #ffffff; float: none;">Profesor a cargo</span></em><br style="color: #000000; font-family: Helvetica; font-size: 12px; font-style: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; background-color: #ffffff;" /><em><span style="color: #808080; font-family: Helvetica; font-size: 12px; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; background-color: #ffffff; float: none;">Departamento de Ciencias de la Computación y de la Decisión</span></em><br style="color: #000000; font-family: Helvetica; font-size: 12px; font-style: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; background-color: #ffffff;" /><em><span style="color: #808080; font-family: Helvetica; font-size: 12px; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; background-color: #ffffff; float: none;">Universidad Nacional de Colombia</span></em>
</h5>
<p>
<span style="font-size: 18pt; font-family: helvetica;"><strong><span style="color: #000000;">Sesión 3 - Introducción a los K Vecinos más cercanos</span></strong></span>
</p>
<p>
<span style="font-size: 14pt; font-family: helvetica;"><strong><span style="color: #000000;">Técnica de clasificación y regresión:</span></strong></span>
</p>
<p>
<span style="color: #000000; font-family: helvetica;"><strong><span style="font-size: 12pt;">1) Clasificación</span></strong></span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica; color: #808080;">Sea <span style="font-size: 14pt;"><em>{ ( X<sub>1</sub> , Y<sub>1</sub>) , … , ( X<sub>n</sub> , Y<sub>n</sub>)  }</em> </span>una m.a donde <span style="font-size: 14pt;"><em>X<sub>i </sub> ϵ R<sup>P </sup>y Y <sub>i </sub>ϵ { C<sub>1</sub>, … ,C<sub>J</sub> } =C</em></span></span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica; color: #808080;">Ahora sea X m.a nueva observación cuya clase <em><span style="font-size: 14pt;">Y ϵ C</span></em></span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica; color: #808080;">se desea predecir,</span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica; color: #808080;">Primero se calculan las instancias de <span style="font-size: 14pt;"><em>X a X<sub>1</sub>, … , Xn</em></span> :</span>
</p>
<p>
<em><span style="font-size: 14pt; font-family: helvetica; color: #808080;">{ X, i = || X - X<sub>i </sub>|| , i=1, … , n }</span></em>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica; color: #808080;">Ahora se define <span style="font-size: 14pt;"><em>E X , <sub>(1)</sub> = min i E X , i</em> </span>(La menor distancia)</span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica; color: #808080;"><span style="font-size: 14pt;"><em> E X , <sub>(2)</sub> = min i E X , i  E X , (I)</em> </span>(La segunda menor distancia)</span>
</p>
<p>
<span style="font-size: 16px; font-family: helvetica; color: #808080;">…</span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica; color: #808080;"><em><span style="font-size: 14pt;">E X , <sub>(n)</sub> = max i E X , i</span> </em>(La mayor distancia)</span>
</p>
<p>
<span style="font-family: helvetica; color: #808080;"></span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica; color: #808080;">Los K Vecinos más cercanos a<em><span style="font-size: 14pt;"> X</span> </em>son los <em><span style="font-size: 14pt;">X<sub>j</sub></span></em> que satisfacen <span style="font-size: 14pt;"><em>|| X –X<sub>j</sub> || &lt; E X , <sub>(K)</sub></em></span></span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica; color: #808080;">Referimos el clasificador de los K Vecinos más cercanos como</span>
</p>
<p>
<span style="font-size: 14pt;"><em><span style="font-family: helvetica; color: #808080;">d: R<sup>P –&gt;</sup></span></em></span><span style="font-size: 14pt;"><em><span style="font-family: helvetica; color: #808080;">C</span></em></span>
</p>
<p>
<span style="font-size: 14pt;"><em><span style="font-family: helvetica; color: #808080;">d( X ) –&gt; arg max j Σ { y<sub>i</sub> = C<sub>j</sub> }, donde || X<sub>i </sub>– X || &lt;  E X , (K)</span></em></span>
</p>
<p>
<span style="font-family: helvetica;"></span>
</p>
<p>
<span style="font-family: helvetica;"><strong><span style="font-size: 12pt; color: #000000;">2) Regresión: </span></strong></span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica;">Es este caso <em><span style="font-size: 14pt;">Yi ϵ R</span></em></span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica;">La función de regresión es:</span>
</p>
<p>
<span style="font-family: helvetica;"><img src="Images/IntroprediccionKNN/1.png" alt="1" width="435" height="75" /></span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica;">Si <em><span style="font-size: 14pt;">X<sub>0 </sub></span></em>es un valor particular, entonces<em><span style="font-size: 14pt;"> f (X<sub>0</sub>)</span></em> es una aproximación de <em><span style="font-size: 14pt;">E [ Y | X = X<sub>0</sub>]</span></em></span>
</p>
<p>
<span style="font-size: 14pt; color: #000000; font-family: helvetica;"><strong>¿Qué es E [ Y| X = X<sub>0</sub>] ?</strong></span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica;">Sea <span style="font-size: 14pt;"><em>( Y, X )</em> </span>una tupla de r.a con fdp conjunta<em><span style="font-size: 14pt;"> f <sub>Y,X </sub>( Y, X).</span></em></span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica;">Dado <em><span style="font-size: 14pt;">X = X<sub>0</sub></span></em> , queremos aproximar <span style="font-size: 14pt;"><em>Y</em></span> por <em><span style="font-size: 14pt;">g ( X )</span></em>, con <span style="font-size: 14pt;"><em>g: R<sup>P </sup>à R</em>.</span></span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica;">El costo cuadrado de g es</span>
</p>
<p>
<span style="font-family: helvetica;"><img src="Images/IntroprediccionKNN/2.png" alt="2" width="545" height="98" /></span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica;">En la expresión azul, <em><span style="text-decoration: underline; font-size: 14pt;">X</span></em> está fija y <span style="font-size: 14pt;"><em>Y</em></span> es la variable de integración. Cuando <em><span style="text-decoration: underline; font-size: 14pt;">X</span></em> está fija entonces</span>
</p>
<p>
<span style="font-size: 14pt;"><em><span style="font-family: helvetica;">f (Y, X) = f <sub>Y|X = X</sub> (y) f<sub>x</sub> (X).</span></em></span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica;">Recordemos que la fdp condicional de Y dado <span style="font-size: 14pt;"><em>X = X<sub>0</sub></em></span> es </span>
</p>
<p>
<span style="font-family: helvetica;"><img src="Images/IntroprediccionKNN/3.png" alt="3" width="501" height="150" /></span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica;"><img src="Images/IntroprediccionKNN/4.png" alt="4" width="124" height="30" />es una función solo de <span style="font-size: 14pt;"><em>y</em></span>. Así</span>
</p>
<p>
<span style="font-family: helvetica;"><img src="Images/IntroprediccionKNN/5.png" alt="5" width="647" height="173" /></span>
</p>
<p>
<span style="font-family: helvetica;"></span>
</p>
<p>
<span style="font-family: helvetica;"><img src="Images/IntroprediccionKNN/6.png" alt="6" width="542" height="58" /></span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica;">La formula (2) indica que para minimizar el costo cuadrático de g() se puede hacer la minimización condicionado sobre X y luego tomando la esperanza con respecto a <span style="text-decoration: underline;">X</span>:</span>
</p>
<p>
<span style="font-family: helvetica;"><img src="Images/IntroprediccionKNN/7.png" alt="7" width="799" height="176" /></span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica;">Para minimizar esta expresión con respecto a C, derivamos con respecto a C e igualamos la derivada a O:</span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica;"><img src="Images/IntroprediccionKNN/8.png" alt="8" width="792" height="212" /></span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica;">Si se reemplaza (5) en (2) se obtiene la pérdida cuadrática de g:</span>
</p>
<p>
<span style="font-family: helvetica;"><img src="Images/IntroprediccionKNN/9.png" alt="9" width="531" height="146" /></span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica;">Por otro lado el MSE o Pérdida Cuadrática del estimador (4) del parámetro δ es:</span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica;"><img src="Images/IntroprediccionKNN/10.png" alt="10" width="987" height="228" /></span>
</p>
<p>
<span style="font-family: helvetica;"></span><span style="font-size: 12pt; font-family: helvetica;">Esto quiere decir que el MSE de <span style="font-size: 14pt;"><em>g()</em></span> se puede ver como:</span>
</p>
<p>
<span style="font-family: helvetica;"><img src="Images/IntroprediccionKNN/11.png" alt="11" width="674" height="152" /></span>
</p>
<p>
<span style="font-size: 12pt; font-family: helvetica;">           </span>
</p>
<div id="ilustracción-de-la-teoría-de-la-predicción-mediante-simulación" class="section level2">
<h2>Ilustracción de la teoría de la predicción mediante simulación</h2>
<p>Dada una muestra <span class="math inline">\(L\left\{(X_1,Y_1),...,(X_n,Y_n)\right\}\)</span>, con <span class="math inline">\(X_i\)</span> toma valores en <span class="math inline">\(\mathbb{R}^p\)</span> y <span class="math inline">\(Y_i\)</span> toma valores en <span class="math inline">\(\mathbb{R}\)</span> y provienen de una distribución conjunta con densidad <span class="math inline">\(f_{Y,X}\left(y,x\right)\)</span>, la función <span class="math inline">\(g(\cdot)\)</span> que minimiza <span class="math inline">\(E[(Y-g(X))^2]\)</span> es <span class="math inline">\(E[Y|X]\)</span>. La pérdida cuadrática de <span class="math inline">\(g(\cdot)\)</span> es <span class="math inline">\(E[V[Y|X]]\)</span>.</p>
<div id="construcción-del-ejemplo-de-simulación" class="section level3">
<h3>Construcción del ejemplo de simulación</h3>
<p>En este ejemplo nos enfocaremos en un caso simple:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(X\)</span> es una varible uniforme discreta, <span class="math inline">\(X \sim U_D[1,5]\)</span></li>
<li><span class="math inline">\(Y|X \sim N\left(X,(\frac{10+X}{10})^2 \right)\)</span></li>
</ol>
<p>El siguiente código simula <span class="math inline">\(X\)</span>:</p>
<pre class="r"><code>set.seed(20200521) # se fija la semilla para obtener resultados reproducibles
N&lt;-2000 # Número de simulaciones
X&lt;-ceiling(runif(n=N,min=0,max=5))</code></pre>
<p>A continuación se explora la distribución muestral de <span class="math inline">\(X\)</span> con un gráfico de barras:</p>
<pre class="r"><code>X_freq_abs&lt;-table(X) # Calcula las frecuencias absolutas
X_freq_rel&lt;-prop.table(X_freq_abs) # Calcula las frecuencias relativas
barplot(X_freq_rel,legend.text =1:5,ylim=c(0,0.6),las=1) # Gráfico de barras de las frecuencias relativas
# barplot(c(X_freq_rel,NA),legend.text =c(1:5,NA),las=1) # Tarea: explorar qué hace esta línea de código.
title(xlab=&quot;Etiqueta&quot;,ylab=&quot;Frecuencia relativa&quot;,
      main=&quot;Distribución muestral de X&quot;)</code></pre>
<p><img src="Teoria_prediccion_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>El siguiente código simula <span class="math inline">\(Y|X\)</span>:</p>
<pre class="r"><code>Y&lt;-rnorm(N,mean=X,sd=(10+X)/10)</code></pre>
<p>Veamos la distribución de <span class="math inline">\(Y|X\)</span>:</p>
<pre class="r"><code>par(mfrow=c(3,2))
hist(Y[X==1],freq=FALSE,main = &quot;Y|X=1&quot;,xlim=c(-2,9),ylim=c(0,0.4),las=1,xlab=&quot;&quot;)
lines(density(Y[X==1],bw=0.5),col=2,lwd=2)
hist(Y[X==2],freq=FALSE,main = &quot;Y|X=2&quot;,xlim=c(-2,9),ylim=c(0,0.4),las=1,xlab=&quot;&quot;)
lines(density(Y[X==2],bw=0.5),col=3,lwd=2)
hist(Y[X==3],freq=FALSE,main = &quot;Y|X=3&quot;,xlim=c(-2,9),ylim=c(0,0.4),las=1,xlab=&quot;&quot;)
lines(density(Y[X==3],bw=0.5),col=4,lwd=2)
hist(Y[X==4],freq=FALSE,main = &quot;Y|X=4&quot;,xlim=c(-2,9),ylim=c(0,0.4),las=1,xlab=&quot;&quot;)
lines(density(Y[X==4],bw=0.5),col=5,lwd=2)
hist(Y[X==4],freq=FALSE,main = &quot;Y|X=5&quot;,xlim=c(-2,9),ylim=c(0,0.4),las=1,xlab=&quot;&quot;)
lines(density(Y[X==5],bw=0.5),col=6,lwd=2)
plot(density(Y[X==1],bw=0.5),col=2,lwd=2,las=1,xlim=c(-2,9),ylim=c(0,0.4),
     main=&quot;Comparación de densidades&quot;,xlab = &quot;Valores de Y&quot;)
lines(density(Y[X==2],bw=0.5),col=3,lwd=2)
lines(density(Y[X==3],bw=0.5),col=4,lwd=2)
lines(density(Y[X==4],bw=0.5),col=5,lwd=2)
lines(density(Y[X==5],bw=0.5),col=6,lwd=2)</code></pre>
<p><img src="Teoria_prediccion_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Otra forma de ver la distribución de <span class="math inline">\(Y|X\)</span>:</p>
<pre class="r"><code># Tomado de:
# https://www.r-graph-gallery.com/2-two-histograms-with-melt-colors.html
hist(Y[X==1],freq=FALSE,border=2,main = &quot;Y|X=x&quot;,xlim=c(-2,9),ylim=c(0,0.4),las=1,xlab=&quot;&quot;,col=rgb(col2rgb(2)[1,1]/255,col2rgb(2)[2,1]/255,col2rgb(2)[3,1]/255,alpha=0.3))

hist(Y[X==2],freq=FALSE,border=3,main = &quot;Y|X=1&quot;,xlim=c(-2,9),ylim=c(0,0.4),las=1,xlab=&quot;&quot;,col=rgb(col2rgb(3)[1,1]/255,col2rgb(3)[2,1]/255,col2rgb(3)[3,1]/255,alpha=0.3),add=TRUE)

hist(Y[X==3],freq=FALSE,border=4,main = &quot;Y|X=1&quot;,xlim=c(-2,9),ylim=c(0,0.4),las=1,xlab=&quot;&quot;,col=rgb(col2rgb(4)[1,1]/255,col2rgb(4)[2,1]/255,col2rgb(4)[3,1]/255,alpha=0.3),add=TRUE)

hist(Y[X==4],freq=FALSE,border=5,main = &quot;Y|X=1&quot;,xlim=c(-2,9),ylim=c(0,0.4),las=1,xlab=&quot;&quot;,col=rgb(col2rgb(5)[1,1]/255,col2rgb(5)[2,1]/255,col2rgb(5)[3,1]/255,alpha=0.3),add=TRUE)

hist(Y[X==5],freq=FALSE,border=6,main = &quot;Y|X=1&quot;,xlim=c(-2,9),ylim=c(0,0.4),las=1,xlab=&quot;&quot;,col=rgb(col2rgb(6)[1,1]/255,col2rgb(6)[2,1]/255,col2rgb(6)[3,1]/255,alpha=0.3),add=TRUE)

legend(&quot;topright&quot;,legend=paste0(&quot;Y|X=&quot;,1:5),col=2:6,lty=1)</code></pre>
<p><img src="Teoria_prediccion_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Veamos la distribución incondicional de <span class="math inline">\(Y\)</span>:</p>
<pre class="r"><code>hist(Y,freq=FALSE,las=1,main=&quot;Histograma de Y&quot;,
     xlab=&quot;Valores de Y&quot;, ylab=&quot;Frecuencia relativa&quot;,
     xlim=c(-2,9),ylim=c(0,0.25),border=&quot;orange&quot;)
lines(density(Y,bw=0.5),col=&quot;orange&quot;,lwd=2)</code></pre>
<p><img src="Teoria_prediccion_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Ahora veamos la distribución conjunta de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>:</p>
<pre class="r"><code>plot(X,Y,las=1,xlab=&quot;X&quot;,ylab=&quot;Y&quot;,main=&quot;X vs Y&quot;,col=X+1)
grid()</code></pre>
<p><img src="Teoria_prediccion_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Otra forma de ver esta distribución es con el boxplot:</p>
<pre class="r"><code>boxplot(Y~X,col=2:6,las=1,main=&quot;Boxplot de Y|X&quot;)</code></pre>
<p><img src="Teoria_prediccion_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Otra alternativa es con las densidades estimadas. Para ello se calculan primero las densidades:</p>
<pre class="r"><code># Estas densidades se calcularon arriba, pero no se guardaron en objetos. Así que hay que volverlas a calcular. Hay que pensar siempre en guardar los cálculos en objetos para evitar los reprocesos.
d1&lt;-density(Y[X==1],bw=0.5)
d2&lt;-density(Y[X==2],bw=0.5)
d3&lt;-density(Y[X==3],bw=0.5)
d4&lt;-density(Y[X==4],bw=0.5)
d5&lt;-density(Y[X==5],bw=0.5)</code></pre>
<p>Ahora se grafican los puntos y se superponen las densidades:</p>
<pre class="r"><code>plot(X,Y,las=1,xlab=&quot;X&quot;,ylab=&quot;Y&quot;,main=&quot;X vs Y&quot;,col=X+1,ylim=c(-2,9),xlim=c(0.5,5.5))
lines(d1$y+1,d1$x,col=2,lwd=2)
lines(d2$y+2,d2$x,col=3,lwd=2)
lines(d3$y+3,d3$x,col=4,lwd=2)
lines(d4$y+4,d4$x,col=5,lwd=2)
lines(d5$y+5,d5$x,col=6,lwd=2)</code></pre>
<p><img src="Teoria_prediccion_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>Las medias condicionales de la variable <span class="math inline">\(Y\)</span> para los diferentes valores de la variable <span class="math inline">\(X\)</span> se pueden obtener así:</p>
<pre class="r"><code>(Y_avg_cond&lt;-aggregate(Y~X,FUN=mean))</code></pre>
<pre><code>##   X        Y
## 1 1 1.095524
## 2 2 2.019659
## 3 3 2.969642
## 4 4 4.145638
## 5 5 4.991957</code></pre>
<p>Lo anterior representa <span class="math inline">\(\hat E[Y|X=x]\)</span>, con <span class="math inline">\(x \in {1,2,3,4,5}\)</span></p>
<p>De manera análoga se pueden calcular las desviaciones estándar condicionales:</p>
<pre class="r"><code>(Y_sd_cond&lt;-aggregate(Y~X,FUN=sd))</code></pre>
<pre><code>##   X        Y
## 1 1 1.033238
## 2 2 1.253522
## 3 3 1.339288
## 4 4 1.337277
## 5 5 1.443761</code></pre>
<p>Lo anterior representa <span class="math inline">\(\hat \sigma_{Y|X=x}=\sqrt{\hat V[Y|X=x]}\)</span>.</p>
<pre class="r"><code>(Y_param&lt;-merge(Y_avg_cond,Y_sd_cond,by=&quot;X&quot;,suffixes = c(&quot;_mean&quot;,&quot;_sd&quot;)))</code></pre>
<pre><code>##   X   Y_mean     Y_sd
## 1 1 1.095524 1.033238
## 2 2 2.019659 1.253522
## 3 3 2.969642 1.339288
## 4 4 4.145638 1.337277
## 5 5 4.991957 1.443761</code></pre>
<p>¿Cuál es el mínimo valor de la función de costo? Este valor teóricamente es <span class="math inline">\(E[V[Y|X]]\)</span>:</p>
<pre class="r"><code>(L_teo&lt;-mean(Y_sd_cond$Y^2))</code></pre>
<pre><code>## [1] 1.661069</code></pre>
<p>¿Cómo se acerca el modelo de regresión lineal a este valor? Primero se ajusta el modelo lineal:</p>
<pre class="r"><code>modelo_lm&lt;-lm(Y~X)</code></pre>
<p>Ahora veamos el error cuadrático medio del modelo lineal:</p>
<pre class="r"><code>(L_lm&lt;-mean(residuals(modelo_lm)^2))</code></pre>
<pre><code>## [1] 1.672597</code></pre>
</div>
<div id="cómo-lo-haría-un-árbol-de-regresión" class="section level3">
<h3>¿Cómo lo haría un árbol de regresión?</h3>
<p>El siguiente código entrena un árbol de regresión:</p>
<pre class="r"><code>library(rpart)
modelo_rt&lt;-rpart(Y~X)</code></pre>
<p>El siguiente código grafica el árbol obtenido:</p>
<pre class="r"><code>plot(modelo_rt,margin=0.03, main=&quot;Resultado de un árbol de regresión&quot;)
text(modelo_rt)</code></pre>
<p><img src="Teoria_prediccion_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>¿Cuál es el valor de la pérdida cuadrática del árbol?</p>
<pre class="r"><code>(L_rt&lt;-mean(residuals(modelo_rt)^2))</code></pre>
<pre><code>## [1] 1.668288</code></pre>
</div>
<div id="cómo-lo-hacen-los-k-vecios-más-cercanos" class="section level3">
<h3>¿Cómo lo hacen los K vecios más cercanos?</h3>
<p>El siguiente código entrena un árbol de regresión:</p>
<pre class="r"><code>library(caret)
modelo_knn&lt;-knnreg(Y~X,data=data.frame(X,Y),k=5)</code></pre>
<p>¿Cuál es la pérdida cuadrática de los KNN con K=5?</p>
<pre class="r"><code>errores_knn&lt;-Y-predict(modelo_knn)
(L_knn&lt;-mean(errores_knn^2))</code></pre>
<pre><code>## [1] 1.668288</code></pre>
</div>
<div id="cómo-lo-hace-un-modelo-lineal-con-varianza-variable" class="section level3">
<h3>¿Cómo lo hace un modelo lineal con varianza variable?</h3>
<p>Se entrena un modelo que considera que la varianza de cada observación es una función de <span class="math inline">\(X\)</span>:</p>
<pre class="r"><code>library(nlme)
modelo_gls&lt;-gls(Y~X,weights=~X)</code></pre>
<!-- El resultado del modelo es el siguiente: -->
<!-- ```{r} -->
<!-- summary(modelo_gls) -->
<!-- ``` -->
<p>¿Cuál es la pérdida cuadrática del modelo lineal con varianza variable?</p>
<pre class="r"><code>(L_gls&lt;-mean(residuals(modelo_gls)^2))</code></pre>
<pre><code>## [1] 1.672705</code></pre>
</div>
</div>
<div id="cómo-se-comparan-las-diferentes-pérdidas" class="section level2">
<h2>¿Cómo se comparan las diferentes pérdidas?</h2>
<p>Veamos cómo se comparan las pérdidas de los modelos anteriores:</p>
<pre class="r"><code>cbind(L_teo,L_lm,L_knn,L_rt,L_gls)</code></pre>
<pre><code>##         L_teo     L_lm    L_knn     L_rt    L_gls
## [1,] 1.661069 1.672597 1.668288 1.668288 1.672705</code></pre>
<h1 style="text-align: right;">
<a href="Sesion3Practica.html"><span style="color: #000000; font-size: 14pt;"><strong>SEGUNDA APLICACIÓN EN R </strong></span></a>
</h1>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
